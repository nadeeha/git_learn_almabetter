Here are two polished slide outlines—one on Self‑Consistency and another on Generated Knowledge Prompting—based on the Prompt Engineering Guide and additional authoritative sources. Since I can't access the content in the shared Google links directly, these slides are built using validated summaries from promptingguide.ai, learnprompting.org, and other reliable references.


---

Slide 1: Self-Consistency

Title: Self-Consistency in Prompt Engineering

Key Points:

1. What It Is

A technique extending Chain‑of‑Thought (CoT) prompting by generating multiple reasoning paths and selecting the most consistent answer.  .



2. How It Works

Run the same prompt multiple times to obtain diverse outputs, then apply majority voting or probability-based selection to decide on the final answer.  .



3. Why It Matters

Boosts accuracy significantly—shown to improve performance on benchmarks like GSM8K, SVAMP, AQuA, StrategyQA, and ARC‑Challenge.  .



4. Advantages

Enhances reliability and reduces errors compared to single‑shot or greedy CoT prompting.  .



5. Implementation Steps

Use CoT prompting as usual.

Enable sampling (e.g., temperature > 0).

Generate multiple outputs.

Aggregate results via majority—or probability marginalization.




Visual Aid Suggestion:
Illustrate the flow: one prompt → multiple CoT paths (A, B, C…) → vote or select consensus → final answer.


---

Slide 2: Generated Knowledge Prompting

Title: Generated Knowledge Prompting: Enhancing Prompt Accuracy

Key Points:

1. Overview

A method that prompts the model to generate relevant facts or knowledge before answering the main question, improving accuracy and context awareness.  .



2. Why It Works

Models often benefit from grounded context—this technique helps anchor responses with generated in‑prompt knowledge.  .



3. Approaches:

Single‑Step: Ask the model to both generate knowledge and respond in one prompt.

Two-Step:

1. Prompt to generate facts.


2. Include those facts in a second prompt to arrive at the final answer.



This second, staged method typically yields more reliable responses.  .



4. Use Cases

Particularly helpful in commonsense reasoning tasks, story generation, or any domain where context or background matters.  .



5. General Benefits

Improves reasoning and factual grounding.

Helps avoid hallucinations or vague answers.

Supports adaptability without full-scale fine-tuning.  .




Visual Aid Suggestion:
Flow diagram: Prompt → generate knowledge → embed knowledge in follow-up prompt → final informed answer.


---

Summary Table

Technique	Core Idea	Strengths

Self-Consistency	Generate multiple CoT outputs and aggregate the most frequent answer	High accuracy, robust reasoning, error reduction
Generated Knowledge	Let the model produce background knowledge before the main response	Better context, greater factual grounding, improved commonsense



---

Tips for Your Presentation

Keep slides visually clean—use bullet points and diagrams.

Use a consistent color palette and clear fonts.

Optionally include brief examples:

Self-Consistency example: math problem “When I was 6, my sister was half my age...” run multiple times → consensus = correct final answer.

Generated Knowledge example: ask “List facts about X,” then “Using those facts, answer the question about X.”



Let me know if you’d like help with actual slide deck formatting (e.g., in PowerPoint or Google Slides), or if you'd like to include real-world examples!
